#!/usr/bin/env python3
"""
AIVIIZN REAL TERMINAL AGENT
Creates BEAUTIFUL, FULLY FUNCTIONAL pages from target sites
No mock code - everything actually works
"""

import os
import sys
import json
import time
import re
import asyncio
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
from urllib.parse import urlparse, urljoin
import logging
from openai import AsyncOpenAI
import tempfile
import shutil

# Real libraries - no mocking
from playwright.async_api import async_playwright, Browser, Page
from supabase import create_client, Client
import anthropic
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# For Excel formula extraction
try:
    import openpyxl
except ImportError:
    openpyxl = None
    print("âš ï¸ openpyxl not installed - Excel formula extraction disabled")
    print("   Run: pip install openpyxl")

# Load environment
load_dotenv()

# Logging setup
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/Users/ianrakow/Desktop/AIVIIZN/agent.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AIVIIZNRealAgent:
    """
    REAL agent that creates BEAUTIFUL, FUNCTIONAL pages
    Everything actually works - no placeholders
    """
    
    def __init__(self):
        """Initialize with real connections"""
        print("ðŸš€ AIVIIZN REAL AGENT - BEAUTIFUL PAGE CREATOR")
        print("=" * 60)
        
        # Real Supabase connection
        self.supabase_url = os.getenv('SUPABASE_URL')
        self.supabase_key = os.getenv('SUPABASE_SERVICE_KEY') 
        self.supabase_anon_key = os.getenv('SUPABASE_KEY')  # Add anon key for templates
        self.supabase: Client = create_client(self.supabase_url, self.supabase_key)
        print("âœ“ Supabase connected")
        
        # Real Claude API - Using Opus 4.1
        self.anthropic_client = anthropic.Anthropic(
            api_key=os.getenv('ANTHROPIC_API_KEY')
        )
        print("âœ“ Claude API ready (Opus 4.1)")
        
        # Initialize OpenAI client
        openai_api_key = os.getenv('OPENAI_API_KEY')
        if openai_api_key:
            self.openai_client = AsyncOpenAI(api_key=openai_api_key)
            print(f"âœ“ GPT-4 Turbo connected (API key: {openai_api_key[:8]}...)")
        else:
            print("âš ï¸ OpenAI API key not found in .env (OPENAI_API_KEY)")
            self.openai_client = None
        
        # Check and create Supabase tables if needed
        self.ensure_database_tables()
        
        # Project paths
        self.project_root = Path("/Users/ianrakow/Desktop/AIVIIZN")
        self.templates_dir = self.project_root / "templates"
        self.static_dir = self.project_root / "static"
        
        # Target site settings
        self.target_base = "https://celticprop.appfolio.com"
        
        # State
        self.processed_pages = self.load_state("processed_pages.json", set())
        self.discovered_links = self.load_state("discovered_links.json", list())
        
        # Real browser instance (persistent)
        self.playwright = None
        self.browser: Optional[Browser] = None
        self.context = None
        self.page: Optional[Page] = None
        
        # Auto mode flag
        self.auto_mode = False
        
        print("âœ“ Ready to create beautiful pages")
    
    def ensure_database_tables(self):
        """Check and create Supabase tables if they don't exist"""
        print("\nðŸ”§ Checking database tables...")
        
        try:
            # Just check if tables exist, don't try RPC
            existing_tables = self.check_existing_tables()
            
            if 'pages' not in existing_tables:
                print("  âš ï¸  'pages' table not found")
                print("  Please create it in Supabase SQL editor")
            else:
                print("    âœ“ 'pages' table exists")
            
            if 'calculations' not in existing_tables:
                print("  âš ï¸  'calculations' table not found")
                print("  Please create it in Supabase SQL editor")
            else:
                print("    âœ“ 'calculations' table exists")
                
            # Add new table for API responses
            if 'api_responses' not in existing_tables:
                print("  âš ï¸  'api_responses' table not found")
                print("  Please create it in Supabase SQL editor with:")
                print("""
                CREATE TABLE api_responses (
                    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
                    page_url TEXT,
                    endpoint TEXT,
                    response_data JSONB,
                    extracted_formulas JSONB,
                    captured_at TIMESTAMPTZ DEFAULT NOW()
                );""")
            else:
                print("    âœ“ 'api_responses' table exists")
                
            print("âœ“ Database ready")
            
        except Exception as e:
            print(f"  âš ï¸ Database check: {e}")
    
    def check_existing_tables(self) -> set:
        """Check which tables exist in Supabase"""
        try:
            # Try to query each table to see if it exists
            existing = set()
            
            # Check pages table
            try:
                self.supabase.table('pages').select('id').limit(1).execute()
                existing.add('pages')
            except:
                pass
                
            # Check calculations table
            try:
                self.supabase.table('calculations').select('id').limit(1).execute()
                existing.add('calculations')
            except:
                pass
                
            # Check api_responses table
            try:
                self.supabase.table('api_responses').select('id').limit(1).execute()
                existing.add('api_responses')
            except:
                pass
                
            return existing
        except:
            return set()
    
    def load_state(self, filename: str, default):
        """Load state from file"""
        file_path = self.project_root / "data" / filename
        if file_path.exists():
            with open(file_path, 'r') as f:
                data = json.load(f)
                return set(data) if isinstance(default, set) else data
        return default
        
    def save_state(self):
        """Save current state"""
        data_dir = self.project_root / "data"
        data_dir.mkdir(exist_ok=True)
        
        with open(data_dir / "processed_pages.json", 'w') as f:
            json.dump(list(self.processed_pages), f, indent=2)
            
        with open(data_dir / "discovered_links.json", 'w') as f:
            json.dump(self.discovered_links, f, indent=2)
            
    async def start_browser(self):
        """Start browser once and keep it open"""
        print("\nðŸŒ Starting browser session...")
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(
            headless=False,
            slow_mo=500,  # Smooth operation
            args=[
                '--start-maximized',
                '--disable-web-security',
                '--disable-features=VizDisplayCompositor',
                '--window-size=1920,1080',
                '--force-device-scale-factor=1'
            ]
        )
        
        # Create page with proper viewport and user agent
        self.context = await self.browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            screen={'width': 1920, 'height': 1080},
            device_scale_factor=1,
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            locale='en-US',
            timezone_id='America/Chicago'
        )
        self.page = await self.context.new_page()
        
        # Set viewport size explicitly
        await self.page.set_viewport_size({"width": 1920, "height": 1080})
        
        # Listen for console messages (for debugging)
        self.page.on('console', lambda msg: print(f"  ðŸ—’ï¸ Console {msg.type}: {msg.text}") if msg.type in ['error', 'warning'] else None)
        
        # Override automation detection
        await self.page.add_init_script("""
            // Remove webdriver property
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
            
            // Override chrome property
            window.chrome = {
                runtime: {}
            };
            
            // Override permissions
            const originalQuery = window.navigator.permissions.query;
            window.navigator.permissions.query = (parameters) => (
                parameters.name === 'notifications' ?
                    Promise.resolve({ state: Notification.permission }) :
                    originalQuery(parameters)
            );
        """)
        
        print("âœ… Browser started with full viewport (1920x1080)")
        
    async def close_browser(self):
        """Close browser at the end"""
        if hasattr(self, 'page') and self.page:
            await self.page.close()
        if hasattr(self, 'context') and self.context:
            await self.context.close()
        if hasattr(self, 'browser') and self.browser:
            await self.browser.close()
        if hasattr(self, 'playwright') and self.playwright:
            await self.playwright.stop()
        print("âœ… Browser closed")
        
    async def run(self):
        """Main execution with persistent browser"""
        print("\nðŸŽ¯ STARTING REAL PAGE REPLICATION")
        print("=" * 60)
        
        # Ask user where to start
        print("\nðŸ“ Where would you like to start?")
        print("  1. Default homepage")
        print("  2. Reports page (/reports)")
        print("  3. Custom URL")
        print("  Or press ENTER for Reports (recommended)")
        
        choice = input("\n>>> Your choice (1/2/3 or ENTER): ").strip()
        
        if choice == "1":
            start_url = self.target_base
            print(f"âœ“ Starting from: {start_url}")
        elif choice == "3":
            custom = input(">>> Enter path (e.g., /reports/rent_roll): ").strip()
            if not custom.startswith('/'):
                custom = '/' + custom
            start_url = self.target_base + custom
            print(f"âœ“ Starting from: {start_url}")
        else:  # Default to 2 or ENTER
            start_url = self.target_base + "/reports"
            print(f"âœ“ Starting from: {start_url} (recommended)")
        
        try:
            # Start browser once
            await self.start_browser()
            
            # Navigate to chosen starting point
            print(f"\nðŸŒ Opening: {start_url}...")
            await self.page.goto(start_url, wait_until='networkidle')
            
            # Wait for manual authorization
            print("\n" + "="*60)
            print("ðŸ”’ MANUAL AUTHORIZATION REQUIRED")
            print("="*60)
            print("\nðŸ‘‰ Please do the following in the browser window:")
            print("   1. Log into the site if needed")
            print("   2. Navigate to any page you want to start with")
            print("   3. Make sure you can see the main content")
            print("\nâš ï¸  BROWSER WILL STAY OPEN - DO NOT CLOSE IT")
            print("\nâœ… When ready, press ENTER in this terminal to continue...")
            
            # Wait for user input
            input("\n>>> Press ENTER to start replication: ")
            
            print("\nðŸš€ Starting replication with persistent browser...")
            
            # REFRESH THE PAGE STATE AFTER USER AUTHORIZATION
            print("\nðŸ”„ Refreshing browser state...")
            await self.page.wait_for_timeout(500)  # Small delay
            
            # Get the ACTUAL current URL after user navigation
            current_url = self.page.url
            print(f"âœ… Current page detected: {current_url}")
            
            # Reload the page to ensure full content loads after login
            if 'sign_in' not in current_url and 'login' not in current_url:
                print("ðŸ”„ Reloading page to ensure full content...")
                await self.page.reload(wait_until='networkidle')
                await self.page.wait_for_timeout(2000)
            
            # Clear any pre-authorization discovered links only if they're login pages
            self.discovered_links = [link for link in self.discovered_links 
                                    if 'sign_in' not in link and 'login' not in link]
            
            # Skip login/sign_in pages
            if 'sign_in' in current_url or 'login' in current_url:
                print("âš ï¸  Still on login page - please navigate to a content page first")
                input("\n>>> Press ENTER after navigating to a content page: ")
                # Re-check current URL
                current_url = self.page.url
                print(f"âœ… New page detected: {current_url}")
            
            # Make sure current URL is in discovered links to process
            if current_url not in self.discovered_links:
                self.discovered_links.insert(0, current_url)
                print(f"ðŸ“¦ Added current page to processing queue")
            
            # Main processing loop - browser stays open
            await self.process_pages_loop()
            
        except KeyboardInterrupt:
            print("\nâš ï¸ Stopped by user (Ctrl+C)")
            self.save_state()
            
        except Exception as e:
            logger.error(f"Agent error: {e}")
            self.save_state()
            raise
            
        finally:
            # Only close browser at the very end
            await self.close_browser()
            
    async def process_pages_loop(self):
        """Process pages with persistent browser"""
        # Get current URL - should already be set from run() method
        current_url = self.page.url
        print(f"\nðŸ“ Processing from: {current_url}")
        
        # Process current page first if not already processed
        if current_url not in self.processed_pages:
            print(f"ðŸŽ‡ Processing current page first...")
            await self.replicate_page_real(current_url)
        else:
            print(f"âœ… Current page already processed, checking for more pages...")
        
        # Process discovered links with user confirmation
        while True:
            unprocessed = [url for url in self.discovered_links 
                          if url not in self.processed_pages]
            
            if not unprocessed:
                print("\nâœ… ALL PAGES PROCESSED!")
                print("\nðŸŽ‰ Session complete - browser will close now")
                break
                
            # Calculate progress
            total_discovered = len(self.discovered_links)
            total_processed = len(self.processed_pages)
            percent_complete = (total_processed / total_discovered * 100) if total_discovered > 0 else 0
            
            # Estimate time remaining (60 seconds per page in auto mode)
            if self.auto_mode:
                time_remaining_seconds = len(unprocessed) * 60
                hours = time_remaining_seconds // 3600
                minutes = (time_remaining_seconds % 3600) // 60
                time_str = f"{hours}h {minutes}m" if hours > 0 else f"{minutes}m"
                print(f"\nðŸ“Š PROGRESS: {total_processed}/{total_discovered} pages ({percent_complete:.1f}% complete)")
                print(f"â±ï¸  Estimated time remaining: {time_str}")
            else:
                print(f"\nðŸ“Š PROGRESS: {total_processed}/{total_discovered} pages ({percent_complete:.1f}% complete)")
            print(f"ðŸ“Š Queue: {len(unprocessed)} pages remaining")
            print(f"ðŸ“ Next: {unprocessed[0]}")
            
            # Ask user if they want to continue
            print("\nOptions:")
            print("  ENTER = Process next page")
            print("  'a' = AUTO mode (process every 60 seconds)")
            print("  'q' = Quit and close browser")
            print("  'l' = List all remaining pages")
            print("  's' = Skip this page")
            print("  'c' = Clear cache and reprocess all")
            
            # Check if we're in auto mode
            if hasattr(self, 'auto_mode') and self.auto_mode:
                print("\nðŸ¤– AUTO MODE: Processing next page in 60 seconds...")
                print("Press Ctrl+C to stop auto mode")
                try:
                    await asyncio.sleep(60)  # 60 seconds (1 minute)
                    response = ''  # Simulate ENTER press
                except KeyboardInterrupt:
                    print("\nâ¹ Auto mode stopped")
                    self.auto_mode = False
                    continue
            else:
                response = input("\n>>> Your choice: ").strip().lower()
            
            if response == 'q':
                print("\nâš ï¸ Stopping at user request")
                break
            elif response == 'a':
                print("\nðŸ¤– AUTO MODE ACTIVATED - Processing every 60 seconds")
                print("Press Ctrl+C during wait to stop auto mode")
                self.auto_mode = True
                await self.replicate_page_real(unprocessed[0])
                await asyncio.sleep(0.5)
                continue
            elif response == 'l':
                print("\nðŸ“‹ Remaining pages:")
                for i, url in enumerate(unprocessed[:10], 1):
                    print(f"  {i}. {url}")
                if len(unprocessed) > 10:
                    print(f"  ... and {len(unprocessed) - 10} more")
                continue
            elif response == 's':
                print(f"â­ï¸ Skipping {unprocessed[0]}")
                self.processed_pages.add(unprocessed[0])
                self.save_state()
                continue
            elif response == 'c':
                print("\nðŸ—‘ï¸ Clearing cache...")
                self.processed_pages.clear()
                self.save_state()
                print("âœ… Cache cleared - all pages will be reprocessed")
                continue
            
            # Process next page (browser stays open)
            await self.replicate_page_real(unprocessed[0])
            
            # Small delay
            await asyncio.sleep(0.5)
            
    async def replicate_page_real(self, url: str):
        """
        REAL page replication - creates BEAUTIFUL, FUNCTIONAL pages
        """
        print(f"\nðŸŽ¨ REPLICATING: {url}")
        print("-" * 50)
        
        # Step 1: Navigate and capture REAL page
        print("[1/6] ðŸŒ Capturing page...")
        page_data = await self.capture_real_page(url)
        
        # Check if capture was successful
        if 'error' in page_data:
            print(f"  âŒ Error capturing page: {page_data['error']}")
            return
        
        # Step 2: Extract EXACT main content
        print("[2/6] ðŸ“¦ Extracting main content...")
        main_content = self.extract_main_content_real(page_data)
        
        # Step 3: Extract and perfect calculations
        print("[3/6] ðŸ§® Perfecting calculations...")
        calculations = await self.extract_calculations_real(main_content)
        
        # Step 4: Generate BEAUTIFUL template
        print("[4/6] ðŸŽ¨ Creating beautiful template...")
        template_path = await self.generate_beautiful_template(url, main_content, calculations)
        
        # Step 5: Store in Supabase (normalized)
        print("[5/6] ðŸ’¾ Storing in database...")
        await self.store_in_supabase_real(url, main_content, calculations, template_path)
        
        # Step 6: Discover new links (use original page_data for better link discovery)
        print("[6/6] ðŸ”— Finding new pages...")
        # Use full page HTML for link discovery, not just main content
        full_page_data = {'html': page_data.get('html', main_content.get('html', ''))}
        new_links = self.discover_links_real(full_page_data)
        
        # Mark complete
        self.processed_pages.add(url)
        self.save_state()
        
        print(f"âœ¨ BEAUTIFUL PAGE COMPLETE: {template_path}")
        print(f"ðŸ”— Found {len(new_links)} new pages")
        
    async def capture_real_page(self, url: str) -> Dict:
        """REAL capture using Playwright with API interception"""
        print(f"  â†’ Navigating to {url}")
        
        api_responses = []
        
        try:
            # Set up API response interception BEFORE navigation
            async def handle_response(response):
                try:
                    content_type = response.headers.get('content-type', '').lower()
                    if 'json' in content_type or '/api/' in response.url:
                        try:
                            data = await response.json()
                            endpoint = response.url.replace(self.target_base, '')
                            api_responses.append({
                                'endpoint': endpoint,
                                'url': response.url,
                                'method': response.request.method,
                                'status': response.status,
                                'data': data,
                                'timestamp': datetime.now().isoformat()
                            })
                            print(f"  ðŸ“Š Captured API: {endpoint}")
                        except:
                            pass  # Not JSON response
                except Exception as e:
                    pass  # Ignore errors in response handling
            
            # Attach the handler
            self.page.on('response', handle_response)
            
            # Navigate to the URL
            await self.page.goto(url, wait_until='networkidle')
            
            # Wait for content to load
            try:
                await self.page.wait_for_selector('main, .main, #main, .content, #content', state='visible', timeout=10000)
            except:
                pass
            
            await self.page.wait_for_load_state('domcontentloaded')
            await self.page.wait_for_load_state('networkidle')
            await self.page.wait_for_timeout(2000)
            
            # Check page dimensions and fix any overlay issues
            page_info = await self.page.evaluate(r"""
                () => {
                    // Remove any modal overlays that might be blocking content
                    const overlays = document.querySelectorAll('.modal-backdrop, .overlay, [class*="overlay"], [class*="modal"]');
                    overlays.forEach(el => {
                        if (el.style.position === 'fixed' || el.style.position === 'absolute') {
                            el.style.display = 'none';
                        }
                    });
                    
                    // Force all content to be visible
                    document.querySelectorAll('*').forEach(el => {
                        if (window.getComputedStyle(el).visibility === 'hidden') {
                            el.style.visibility = 'visible';
                        }
                        if (window.getComputedStyle(el).opacity === '0') {
                            el.style.opacity = '1';
                        }
                    });
                    
                    // Expand body height if needed
                    document.body.style.minHeight = '100vh';
                    document.documentElement.style.minHeight = '100vh';
                    
                    // Scroll to bottom to load all content
                    window.scrollTo(0, document.body.scrollHeight);
                    
                    // Return page dimensions for debugging
                    return {
                        bodyHeight: document.body.scrollHeight,
                        viewportHeight: window.innerHeight,
                        hasScroll: document.body.scrollHeight > window.innerHeight
                    };
                }
            """)
            
            print(f"  â†’ Page dimensions: {page_info['bodyHeight']}px height, viewport: {page_info['viewportHeight']}px")
            
            # Scroll back to top
            await self.page.evaluate("window.scrollTo(0, 0)")
            
            # Wait a bit more for any lazy-loaded content
            await self.page.wait_for_timeout(1000)
            
            # Get real HTML
            html_content = await self.page.content()
            
            # Get page title
            title = await self.page.title()
            
            # Take screenshot for reference
            screenshot_path = self.project_root / "data" / "screenshots" / f"{url.split('/')[-1]}.png"
            screenshot_path.parent.mkdir(parents=True, exist_ok=True)
            
            try:
                await self.page.screenshot(path=str(screenshot_path), full_page=True)
                print("  â†’ Full page screenshot captured")
            except:
                await self.page.screenshot(path=str(screenshot_path))
                print("  â†’ Viewport screenshot captured")
            
            print(f"  âœ“ Page captured with {len(api_responses)} API responses")
            
            return {
                'url': url,
                'title': title,
                'html': html_content,
                'api_responses': api_responses,  # Add captured API data
                'forms': [],  # Simplified for now
                'tables': [],
                'scripts': '',
                'screenshot': str(screenshot_path),
                'captured_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Error capturing page: {e}")
            return {'url': url, 'error': str(e)}
            
    def extract_main_content_real(self, page_data: Dict) -> Dict:
        """
        Extract ONLY the main content area - remove site navigation
        """
        print("  â†’ Parsing HTML with BeautifulSoup")
        
        soup = BeautifulSoup(page_data['html'], 'html.parser')
        
        # Remove site navigation and header
        for selector in [
            'header', '.header', '#header',
            'nav', '.nav', '.navigation', 
            '.sidebar', '#sidebar',
            '.footer', '#footer',
            '.site-header', '.site-nav'
        ]:
            for element in soup.select(selector):
                element.decompose()
                
        # Find main content area
        main_content = None
        for selector in [
            'main', '.main', '#main',
            '.content', '#content', 
            '.main-content', '#main-content',
            '.page-content', '#page-content',
            '.body-content', '#body-content'
        ]:
            main_content = soup.select_one(selector)
            if main_content:
                break
                
        if not main_content:
            # Fallback: find largest div with substantial content
            divs = soup.find_all('div')
            main_content = max(divs, key=lambda d: len(d.get_text()), default=soup.body)
            
        print("  âœ“ Main content extracted")
        
        return {
            'html': str(main_content) if main_content else '',
            'api_responses': page_data.get('api_responses', []),  # Pass through API responses
            'forms': page_data.get('forms', []),
            'tables': page_data.get('tables', []),
            'scripts': page_data.get('scripts', ''),
            'title': page_data.get('title', ''),
            'url': page_data.get('url', '')
        }
        
    async def reverse_engineer_calculations(self) -> List[Dict]:
        """Deduce formulas by changing inputs and observing outputs"""
        print("  ðŸ”¬ Reverse engineering calculations...")
        
        observations = []
        
        try:
            # Find all input elements that might affect calculations
            inputs = await self.page.query_selector_all('input[type="number"], input[type="text"]:not([readonly]), select, input[type="checkbox"]')
            
            print(f"    Found {len(inputs)} inputs to test")
            
            for i, input_element in enumerate(inputs[:3]):  # Test first 3 inputs
                try:
                    # Get initial state
                    initial_values = await self.page.evaluate(r"""
                        () => ({
                            totals: Array.from(document.querySelectorAll('[class*="total"], [class*="sum"], [class*="amount"], td:last-child')).map(el => ({
                                text: el.textContent,
                                value: parseFloat(el.textContent.replace(/[^0-9.-]/g, ''))
                            })).filter(item => !isNaN(item.value))
                        })
                    """)
                    
                    # Get input type and current value
                    input_type = await input_element.get_attribute('type')
                    current_value = await input_element.input_value()
                    
                    # Change the input based on type
                    if input_type == 'checkbox':
                        await input_element.click()
                        await self.page.wait_for_timeout(1000)
                    else:
                        # Try changing to a known value
                        await input_element.fill('100')
                        # Trigger change event
                        await input_element.press('Tab')
                        await self.page.wait_for_timeout(1500)
                    
                    # Get new state
                    new_values = await self.page.evaluate(r"""
                        () => ({
                            totals: Array.from(document.querySelectorAll('[class*="total"], [class*="sum"], [class*="amount"], td:last-child')).map(el => ({
                                text: el.textContent,
                                value: parseFloat(el.textContent.replace(/[^0-9.-]/g, ''))
                            })).filter(item => !isNaN(item.value))
                        })
                    """)
                    
                    # Compare and deduce
                    for j, initial in enumerate(initial_values.get('totals', [])):
                        if j < len(new_values.get('totals', [])):
                            new = new_values['totals'][j]
                            if initial['value'] != new['value']:
                                change = new['value'] - initial['value']
                                observations.append({
                                    'input_changed': f'Input #{i+1} set to 100',
                                    'output_changed': f"{initial['value']} -> {new['value']}",
                                    'delta': change,
                                    'likely_formula': f"multiplied by {change/100:.2f}" if change else "no change",
                                    'element_text': initial.get('text', '')
                                })
                                print(f"      âœ“ Found relationship: {initial['value']} -> {new['value']} (delta: {change})")
                    
                    # Reset the input
                    if input_type == 'checkbox':
                        await input_element.click()
                    else:
                        await input_element.fill(current_value if current_value else '')
                    await self.page.wait_for_timeout(500)
                    
                except Exception as e:
                    print(f"      âš ï¸ Error testing input {i+1}: {e}")
                    continue
                    
        except Exception as e:
            print(f"    âš ï¸ Reverse engineering error: {e}")
            
        return observations

    async def extract_excel_formulas(self) -> Dict:
        """Click export to Excel and intercept to get formulas"""
        print("  ðŸ“Š Looking for Excel export...")
        
        if not openpyxl:
            print("    âš ï¸ openpyxl not installed - skipping Excel extraction")
            return {}
        
        try:
            # Find and click export button
            export_btn = await self.page.query_selector('button:has-text("Excel"), a:has-text("Export"), button:has-text("Download"), button:has-text("XLS"), a:has-text("Excel")')
            
            if not export_btn:
                print("    No Excel export button found")
                return {}
                
            print("    âœ“ Found export button, clicking...")
            
            # Set up download handler
            async with self.page.expect_download() as download_info:
                await export_btn.click()
                download = await download_info.value
                
                # Save the file temporarily
                temp_path = tempfile.mktemp(suffix='.xlsx')
                await download.save_as(temp_path)
                print(f"    âœ“ Excel file downloaded")
                
                # Read the Excel file
                wb = openpyxl.load_workbook(temp_path, data_only=False)  # Keep formulas
                formulas = {}
                
                for sheet_name in wb.sheetnames:
                    sheet = wb[sheet_name]
                    sheet_formulas = []
                    
                    for row in sheet.iter_rows():
                        for cell in row:
                            # Excel formulas start with =
                            if cell.value and str(cell.value).startswith('='):
                                sheet_formulas.append({
                                    'cell': cell.coordinate,
                                    'formula': str(cell.value),
                                    'row': cell.row,
                                    'column': cell.column
                                })
                                print(f"      âœ“ Found formula in {sheet_name}!{cell.coordinate}: {cell.value}")
                    
                    if sheet_formulas:
                        formulas[sheet_name] = sheet_formulas
                
                # Clean up temp file
                try:
                    os.remove(temp_path)
                except:
                    pass
                    
                print(f"    âœ“ Extracted {sum(len(f) for f in formulas.values())} formulas from {len(formulas)} sheets")
                return formulas
                
        except Exception as e:
            print(f"    âš ï¸ Excel export error: {e}")
            return {}

    async def analyze_calculation_triggers(self) -> List[Dict]:
        """Monitor what user actions trigger calculation API calls"""
        print("  ðŸŽ¯ Analyzing calculation triggers...")
        
        calculation_patterns = []
        captured_requests = []
        
        # Set up request monitoring
        async def handle_request(request):
            try:
                url = request.url
                # Look for calculation endpoints
                calc_keywords = ['calculate', 'total', 'sum', 'compute', 'aggregate', 'report', 'formula', 'balance']
                if any(keyword in url.lower() for keyword in calc_keywords):
                    post_data = None
                    if request.method == 'POST':
                        try:
                            post_data = request.post_data
                        except:
                            pass
                    
                    captured_requests.append({
                        'endpoint': url.replace(self.target_base, ''),
                        'url': url,
                        'method': request.method,
                        'post_data': post_data,
                        'timestamp': datetime.now().isoformat()
                    })
                    print(f"      ðŸ“¡ Captured calculation endpoint: {url.split('/')[-1]}")
            except:
                pass
        
        # Attach the handler
        self.page.on('request', handle_request)
        
        # Trigger common calculation actions
        actions = [
            'button:has-text("Calculate")',
            'button:has-text("Update")',
            'button:has-text("Refresh")',
            'button:has-text("Apply")',
            'button:has-text("Generate")',
            'button:has-text("Run")',
            'input[type="date"]',
            'select'
        ]
        
        for selector in actions:
            try:
                element = await self.page.query_selector(selector)
                if element:
                    if 'input' in selector or 'select' in selector:
                        # Change value for inputs/selects
                        if 'date' in selector:
                            await element.fill('2024-01-01')
                        elif 'select' in selector:
                            await element.select_option(index=1)
                    else:
                        # Click buttons
                        await element.click()
                    
                    # Wait for potential API calls
                    await self.page.wait_for_timeout(1500)
                    
                    # Check if we captured anything new
                    if len(captured_requests) > len(calculation_patterns):
                        new_patterns = captured_requests[len(calculation_patterns):]
                        calculation_patterns.extend(new_patterns)
                        print(f"      âœ“ Action '{selector}' triggered {len(new_patterns)} API calls")
                        
            except:
                continue
        
        # Remove the handler
        self.page.remove_listener('request', handle_request)
        
        print(f"    âœ“ Found {len(calculation_patterns)} calculation triggers")
        return calculation_patterns

    async def extract_formula_comments(self) -> List[Dict]:
        """Extract formulas from JavaScript comments and data attributes"""
        print("  ðŸ’­ Mining source code for formula comments...")
        
        formulas_found = await self.page.evaluate(r"""
            () => {
                const formulas = [];
                
                // Check all script tags for comments
                document.querySelectorAll('script').forEach(script => {
                    const text = script.innerHTML;
                    
                    // Look for formula patterns in comments
                    const formulaComments = text.match(/\/\/.*(?:formula|calculate|equation|sum|total|rate|percentage).*$/gmi);
                    if (formulaComments) {
                        formulaComments.forEach(comment => {
                            formulas.push({
                                type: 'comment',
                                content: comment,
                                source: 'script'
                            });
                        });
                    }
                    
                    // Look for calculation functions
                    const calcFunctions = text.match(/function.*(?:calculate|compute|total|sum|get.*(?:Total|Sum|Amount|Rate))[^{]*{[^}]+}/gi);
                    if (calcFunctions) {
                        calcFunctions.forEach(func => {
                            formulas.push({
                                type: 'function',
                                content: func.substring(0, 500), // Limit length
                                source: 'script'
                            });
                        });
                    }
                    
                    // Look for mathematical operations
                    const mathPatterns = text.match(/(?:total|sum|amount|rate|percentage)\s*[=:]\s*[^;]+[+\-*/][^;]+/gi);
                    if (mathPatterns) {
                        mathPatterns.forEach(pattern => {
                            formulas.push({
                                type: 'calculation',
                                content: pattern,
                                source: 'script'
                            });
                        });
                    }
                });
                
                // Check data attributes
                document.querySelectorAll('[data-formula], [data-calculation], [data-equation], [data-rate], [data-percentage]').forEach(el => {
                    const attrs = {};
                    for (let attr of el.attributes) {
                        if (attr.name.startsWith('data-')) {
                            attrs[attr.name] = attr.value;
                        }
                    }
                    formulas.push({
                        type: 'data-attribute',
                        element: el.tagName,
                        attributes: attrs,
                        value: el.textContent.trim().substring(0, 100),
                        source: 'html'
                    });
                });
                
                // Check title attributes (often used for tooltips explaining calculations)
                document.querySelectorAll('[title*="calculated"], [title*="formula"], [title*="sum"], [title*="total"], [title*="rate"]').forEach(el => {
                    formulas.push({
                        type: 'tooltip',
                        tooltip: el.title,
                        value: el.textContent.trim().substring(0, 100),
                        source: 'html'
                    });
                });
                
                return formulas;
            }
        """)
        
        print(f"    âœ“ Found {len(formulas_found)} formula hints in source")
        return formulas_found

    async def deduce_formulas_from_patterns(self) -> List[Dict]:
        """Navigate to similar pages and compare to find patterns"""
        print("  ðŸ”„ Comparing similar pages to deduce formulas...")
        
        # Collect data from current page first
        current_data = await self.page.evaluate(r"""
            () => {
                const data = {};
                
                // Collect all numeric values with their labels
                document.querySelectorAll('*').forEach(el => {
                    const text = el.textContent.trim();
                    const match = text.match(/^\$?([\d,]+\.?\d*)%?$/);
                    
                    if (match && el.children.length === 0) {  // Leaf nodes only
                        // Try to find a label
                        const label = el.closest('tr')?.firstElementChild?.textContent?.trim() ||
                                     el.previousElementSibling?.textContent?.trim() ||
                                     el.parentElement?.firstElementChild?.textContent?.trim() ||
                                     el.getAttribute('aria-label') ||
                                     el.closest('[data-label]')?.dataset.label ||
                                     'unknown';
                        
                        const value = parseFloat(match[1].replace(/,/g, ''));
                        
                        if (label && label !== 'unknown' && !isNaN(value)) {
                            // Store multiple values for same label
                            if (!data[label]) data[label] = [];
                            data[label].push(value);
                        }
                    }
                });
                
                // Also collect date filters if present
                const dateInputs = document.querySelectorAll('input[type="date"], select[name*="month"], select[name*="year"]');
                const dateFilters = {};
                dateInputs.forEach(input => {
                    dateFilters[input.name || input.type] = input.value;
                });
                
                return { values: data, filters: dateFilters, url: window.location.href };
            }
        """)
        
        data_points = [current_data]
        print(f"    âœ“ Collected baseline data: {len(current_data.get('values', {}))} metrics")
        
        # Try to find and test filter controls
        date_filters = await self.page.query_selector_all('select[name*="month"], select[name*="year"], input[type="date"]')
        
        if date_filters:
            print(f"    Found {len(date_filters)} date filters to test")
            
            # Try changing date filters to get comparative data
            for i in range(min(2, len(date_filters))):  # Test up to 2 different dates
                try:
                    filter_element = date_filters[0]  # Use first filter
                    filter_type = await filter_element.get_attribute('type') or 'select'
                    
                    if filter_type == 'date':
                        # Change date
                        await filter_element.fill('2024-02-01')
                    else:
                        # Change select option
                        options = await filter_element.query_selector_all('option')
                        if len(options) > i + 1:
                            await filter_element.select_option(index=i + 1)
                    
                    # Apply changes
                    apply_btn = await self.page.query_selector('button:has-text("Apply"), button:has-text("Go"), button:has-text("Submit"), button[type="submit"]')
                    if apply_btn:
                        await apply_btn.click()
                        await self.page.wait_for_timeout(2000)
                    
                    # Collect new data
                    new_data = await self.page.evaluate(r"""
                        () => {
                            const data = {};
                            document.querySelectorAll('*').forEach(el => {
                                const text = el.textContent.trim();
                                const match = text.match(/^\$?([\d,]+\.?\d*)%?$/);
                                if (match && el.children.length === 0) {
                                    const label = el.closest('tr')?.firstElementChild?.textContent?.trim() ||
                                                 el.previousElementSibling?.textContent?.trim() ||
                                                 'unknown';
                                    const value = parseFloat(match[1].replace(/,/g, ''));
                                    if (label && label !== 'unknown' && !isNaN(value)) {
                                        if (!data[label]) data[label] = [];
                                        data[label].push(value);
                                    }
                                }
                            });
                            const dateInputs = document.querySelectorAll('input[type="date"], select[name*="month"], select[name*="year"]');
                            const dateFilters = {};
                            dateInputs.forEach(input => {
                                dateFilters[input.name || input.type] = input.value;
                            });
                            return { values: data, filters: dateFilters };
                        }
                    """)
                    
                    data_points.append(new_data)
                    print(f"      âœ“ Collected comparison data point {i+2}")
                    
                except Exception as e:
                    print(f"      âš ï¸ Error collecting comparison: {e}")
                    continue
        
        # Analyze patterns
        formulas = self.analyze_patterns(data_points)
        
        print(f"    âœ“ Deduced {len(formulas)} formulas from patterns")
        return formulas

    def analyze_patterns(self, data_points: List[Dict]) -> List[Dict]:
        """Analyze data patterns to deduce formulas"""
        formulas = []
        
        if len(data_points) < 2:
            return formulas
        
        # Compare values across data points
        all_labels = set()
        for dp in data_points:
            all_labels.update(dp.get('values', {}).keys())
        
        for label in all_labels:
            values_across_points = []
            for dp in data_points:
                if label in dp.get('values', {}):
                    vals = dp['values'][label]
                    # Take first value if multiple
                    values_across_points.append(vals[0] if vals else 0)
            
            if len(values_across_points) >= 2:
                # Check for patterns
                
                # Pattern 1: Constant values (likely input data)
                if all(v == values_across_points[0] for v in values_across_points):
                    formulas.append({
                        'name': f"get_{label.replace(' ', '_').lower()}",
                        'description': f"Static value for {label}",
                        'formula': f"constant = {values_across_points[0]}",
                        'type': 'constant',
                        'variables': [],
                        'javascript': f"function get_{label.replace(' ', '_').lower()}() {{ return {values_across_points[0]}; }}"
                    })
                
                # Pattern 2: Check if it's a sum of other values
                for other_label in all_labels:
                    if other_label != label:
                        other_values = []
                        for dp in data_points:
                            if other_label in dp.get('values', {}):
                                vals = dp['values'][other_label]
                                other_values.append(vals[0] if vals else 0)
                        
                        # Check if current is sum of others
                        if len(other_values) == len(values_across_points):
                            # This is simplified - in reality would check multiple labels
                            pass
                
                # Pattern 3: Percentage relationships
                if '%' in label or 'rate' in label.lower():
                    formulas.append({
                        'name': f"calculate_{label.replace(' ', '_').replace('%', 'percent').lower()}",
                        'description': f"Calculate {label}",
                        'formula': "(numerator / denominator) * 100",
                        'type': 'percentage',
                        'variables': ['numerator', 'denominator'],
                        'javascript': f"function calculate_{label.replace(' ', '_').replace('%', 'percent').lower()}(num, denom) {{ return denom > 0 ? (num / denom * 100).toFixed(2) : 0; }}"
                    })
        
        return formulas

    async def enhanced_gpt4_analysis(self, observations: List[Dict], api_data: List[Dict] = None) -> List[Dict]:
        """Use GPT-4 Turbo for intelligent formula analysis and naming"""
        print("  ðŸ§  GPT-4 Turbo mathematical analysis...")
        
        # Check if OpenAI client is initialized
        if not self.openai_client:
            print("    âš ï¸ OpenAI API key not found in .env (OPENAI_API_KEY)")
            return []
        
        gpt4_calculations = []
        
        try:
            # Test connection first
            print("    â†’ Testing GPT-4 connection...")
            test_response = await self.openai_client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[{"role": "user", "content": "Calculate 5% of 1000"}],
                max_tokens=50
            )
            print(f"      âœ“ GPT-4 API responding: {test_response.choices[0].message.content.strip()}")
            
            # 1. Analyze reverse engineering observations
            if observations:
                print("    â†’ Analyzing numerical patterns with GPT-4...")
                
                obs_data = []
                for obs in observations[:10]:
                    if 'delta' in obs and obs['delta'] != 0:
                        obs_data.append({
                            'input_changed': obs.get('input_changed', ''),
                            'output_changed': obs.get('output_changed', ''),
                            'delta': obs.get('delta', 0),
                            'element': obs.get('element_text', '')
                        })
                
                if obs_data:
                    prompt = f"""You are analyzing a property management system (similar to AppFolio). 
Based on these observations from changing inputs and watching outputs, identify the mathematical formulas being used.

OBSERVATIONS FROM TESTING:
{json.dumps(obs_data, indent=2)}

CONTEXT: This is a property management system that handles:
- Rent collection and rent rolls
- Late fees (typically 5% of rent)
- Security deposits (usually 1-2 months rent)
- CAM charges (Common Area Maintenance)
- Management fees (typically 8-10% of gross rent)
- Occupancy rates and vacancy calculations
- Proration for partial months
- Utility billing and RUBS (Ratio Utility Billing System)
- Maintenance reserves
- Pet fees and deposits

Analyze the patterns and return a JSON array of identified formulas. Each formula should have:
- A proper camelCase name describing what it calculates
- The mathematical formula
- Variables involved
- Confidence level
- JavaScript implementation

IMPORTANT: Focus on identifying the ACTUAL formulas used based on the numerical evidence.

Return ONLY a JSON array like this:
[
  {{
    "name": "calculateLateFee",
    "description": "Late fee calculation for overdue rent",
    "formula": "lateFee = monthlyRent * 0.05",
    "variables": ["monthlyRent"],
    "confidence": "high",
    "evidence": "When input changed to 100, output changed proportionally by 5%",
    "javascript": "function calculateLateFee(monthlyRent) {{ return monthlyRent * 0.05; }}"
  }}
]"""

                    response = await self.openai_client.chat.completions.create(
                        model="gpt-4-turbo-preview",
                        messages=[{"role": "user", "content": prompt}],
                        temperature=0,
                        max_tokens=2000,
                        response_format={ "type": "json_object" }
                    )
                    
                    try:
                        result = json.loads(response.choices[0].message.content)
                        # Handle different possible JSON structures
                        formulas = result.get('formulas', result) if isinstance(result, dict) else result
                        if not isinstance(formulas, list):
                            formulas = [formulas]
                        
                        for formula in formulas:
                            if isinstance(formula, dict) and 'name' in formula:
                                formula['source'] = 'gpt4_observation_analysis'
                                formula['is_gpt4'] = True  # CRITICAL: Mark as GPT-4 formula
                                gpt4_calculations.append(formula)
                                print(f"      âœ“ GPT-4 identified: {formula['name']} - {formula.get('description', '')}")
                    except json.JSONDecodeError as e:
                        print(f"      âš ï¸ JSON parse error: {e}")
            
            # 2. Analyze API response patterns
            if api_data:
                print("    â†’ Analyzing API data patterns with GPT-4...")
                
                # Prepare API data summary
                api_summary = []
                for response in api_data[:5]:
                    if response.get('data'):
                        numbers = self.extract_numbers_from_dict(response['data'])
                        api_summary.append({
                            'endpoint': response['endpoint'],
                            'sample_numbers': numbers[:20],
                            'data_structure': self.get_data_structure(response['data'])
                        })
                
                if api_summary:
                    prompt = f"""Analyze these API responses from a property management system to identify calculation formulas.

API RESPONSES:
{json.dumps(api_summary, indent=2)}

These endpoints likely calculate:
- Rent rolls (sum of all rents)
- Occupancy rates (occupied units / total units * 100)
- Revenue calculations
- Outstanding balances
- Aged receivables (30/60/90 days)
- Vacancy loss
- Net operating income (NOI)

Identify the formulas based on the data patterns. Return a JSON array of formulas with proper names and implementations.

Focus on formulas you can confidently identify from the numerical patterns."""

                    response = await self.openai_client.chat.completions.create(
                        model="gpt-4-turbo-preview",
                        messages=[{"role": "user", "content": prompt}],
                        temperature=0,
                        max_tokens=1500,
                        response_format={ "type": "json_object" }
                    )
                    
                    try:
                        result = json.loads(response.choices[0].message.content)
                        formulas = result.get('formulas', result) if isinstance(result, dict) else result
                        if not isinstance(formulas, list):
                            formulas = [formulas]
                        
                        for formula in formulas:
                            if isinstance(formula, dict) and 'name' in formula:
                                formula['source'] = 'gpt4_api_analysis'
                                formula['is_gpt4'] = True  # CRITICAL: Mark as GPT-4 formula
                                gpt4_calculations.append(formula)
                                print(f"      âœ“ GPT-4 found in API: {formula['name']}")
                    except json.JSONDecodeError as e:
                        print(f"      âš ï¸ API analysis JSON error: {e}")
            
            # 3. Property management domain-specific formulas
            print("    â†’ Checking standard property management formulas...")
            
            domain_prompt = """Based on property management industry standards, provide the most common calculation formulas.

Return a JSON array with these standard formulas:
1. Late fee calculation (typically 5% of rent)
2. Proration formula for partial month rent
3. Occupancy rate calculation
4. Vacancy rate calculation
5. Security deposit (usually 1-2x monthly rent)
6. CAM charges calculation
7. Management fee (typically 8-10% of gross rent)
8. RUBS (Ratio Utility Billing) calculation
9. Pet deposit/fee calculations
10. Gross rent multiplier

Each formula should include the industry-standard calculation with proper naming and JavaScript implementation."""

            response = await self.openai_client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[{"role": "user", "content": domain_prompt}],
                temperature=0,
                max_tokens=2000,
                response_format={ "type": "json_object" }
            )
            
            try:
                result = json.loads(response.choices[0].message.content)
                formulas = result.get('formulas', result) if isinstance(result, dict) else result
                if not isinstance(formulas, list):
                    formulas = [formulas]
                
                # Only add domain formulas if we have confidence they apply
                for formula in formulas[:5]:  # Limit to top 5 most relevant
                    if isinstance(formula, dict) and 'name' in formula:
                        formula['source'] = 'gpt4_domain_knowledge'
                                formula['is_gpt4'] = True  # CRITICAL: Mark as GPT-4 formula
                        formula['confidence'] = formula.get('confidence', 'medium')
                        gpt4_calculations.append(formula)
                        print(f"      âœ“ Standard formula: {formula['name']}")
            except json.JSONDecodeError as e:
                print(f"      âš ï¸ Domain formula JSON error: {e}")
            
            print(f"    âœ“ GPT-4 identified {len(gpt4_calculations)} total calculations")
            return gpt4_calculations
            
        except Exception as e:
            logger.error(f"GPT-4 analysis error: {e}")
            print(f"    âŒ GPT-4 analysis failed: {e}")
            return []

    def get_data_structure(self, data: Any, depth: int = 0) -> Dict:
        """Extract data structure for GPT-4 analysis"""
        if depth > 2:  # Limit depth to avoid huge structures
            return {"type": type(data).__name__}
        
        if isinstance(data, dict):
            structure = {"type": "dict", "keys": {}}
            for key in list(data.keys())[:10]:  # Limit to first 10 keys
                structure["keys"][key] = self.get_data_structure(data[key], depth + 1)
            return structure
        elif isinstance(data, list):
            if len(data) > 0:
                return {"type": "list", "length": len(data), "sample": self.get_data_structure(data[0], depth + 1)}
            return {"type": "list", "length": 0}
        else:
            return {"type": type(data).__name__, "value": str(data)[:50] if not isinstance(data, (int, float)) else data}

    def extract_numbers_from_dict(self, data: Any) -> List[float]:
        """Extract all numbers from a nested dictionary/list structure"""
        numbers = []
        
        if isinstance(data, dict):
            for value in data.values():
                numbers.extend(self.extract_numbers_from_dict(value))
        elif isinstance(data, list):
            for item in data:
                numbers.extend(self.extract_numbers_from_dict(item))
        elif isinstance(data, (int, float)):
            numbers.append(float(data))
        elif isinstance(data, str):
            # Try to extract numbers from strings
            import re
            matches = re.findall(r'-?\d+\.?\d*', data)
            for match in matches:
                try:
                    numbers.append(float(match))
                except:
                    pass
        
        return numbers

    async def extract_calculations_real(self, main_content: Dict) -> List[Dict]:
        """Extract REAL calculations using multiple advanced methods"""
        print("  â†’ Extracting calculations using advanced methods")
        
        all_calculations = []
        
        # Method 1: Try Excel export first (most accurate)
        excel_formulas = await self.extract_excel_formulas()
        if excel_formulas:
            print(f"    âœ“ Excel formulas extracted: {len(excel_formulas)} sheets")
            # Convert Excel formulas to our format
            for sheet_name, formulas in excel_formulas.items():
                for formula in formulas:
                    all_calculations.append({
                        'name': f"excel_{sheet_name}_{formula['cell']}",
                        'description': f"Excel formula from {sheet_name}!{formula['cell']}",
                        'formula': formula['formula'],
                        'source': 'excel',
                        'verified': True,
                        'javascript': self.convert_excel_to_js(formula['formula'])
                    })
        
        # Method 2: Reverse engineering
        observations = await self.reverse_engineer_calculations()
        if observations:
            print(f"    âœ“ Reverse engineered: {len(observations)} relationships")
            for obs in observations:
                all_calculations.append({
                    'name': f"deduced_{obs.get('element_text', 'calc').replace(' ', '_').lower()[:20]}",
                    'description': f"Deduced from input changes: {obs['output_changed']}",
                    'formula': obs.get('likely_formula', 'unknown'),
                    'source': 'reverse_engineering',
                    'verified': False,
                    'delta': obs.get('delta', 0)
                })
        
        # Method 3: API trigger analysis
        api_triggers = await self.analyze_calculation_triggers()
        if api_triggers:
            print(f"    âœ“ API triggers found: {len(api_triggers)} endpoints")
            for trigger in api_triggers:
                all_calculations.append({
                    'name': f"api_{trigger['endpoint'].split('/')[-1]}",
                    'description': f"Calculation API: {trigger['endpoint']}",
                    'endpoint': trigger['endpoint'],
                    'method': trigger['method'],
                    'source': 'api_trigger'
                })
        
        # Method 4: Source code mining
        source_formulas = await self.extract_formula_comments()
        if source_formulas:
            print(f"    âœ“ Source code formulas: {len(source_formulas)} hints")
            for sf in source_formulas[:5]:  # Limit to avoid too many
                if sf.get('type') == 'function' and 'calculate' in sf.get('content', '').lower():
                    all_calculations.append({
                        'name': f"source_{sf['type']}",
                        'description': "Found in source code",
                        'formula': sf.get('content', '')[:200],
                        'source': 'source_code',
                        'verified': False
                    })
        
        # Method 5: Pattern deduction
        pattern_formulas = await self.deduce_formulas_from_patterns()
        if pattern_formulas:
            print(f"    âœ“ Pattern formulas: {len(pattern_formulas)} deduced")
            all_calculations.extend(pattern_formulas)
        
        # Get API responses
        api_responses = main_content.get('api_responses', [])
        
        # ENHANCED: Use GPT-4 Turbo instead of Wolfram
        print("    â†’ Starting GPT-4 Turbo analysis...")
        gpt4_results = await self.enhanced_gpt4_analysis(observations, api_responses)
        
        if gpt4_results:
            print(f"    âœ“ GPT-4 found {len(gpt4_results)} formulas")
            # DEBUG: Track GPT-4 formulas
            for formula in gpt4_results:
                formula['is_gpt4'] = True  # Mark GPT-4 formulas
            all_calculations.extend(gpt4_results)
            print(f"    ðŸ“Š Total calculations: {len(all_calculations)}")
            gpt4_count = sum(1 for c in all_calculations if c.get('is_gpt4'))
            print(f"    ðŸ¤– GPT-4 formulas: {gpt4_count}")
        
        # Send everything to Claude for final synthesis (keeping your existing flow)
        if all_calculations or api_responses:
            print("    â†’ Sending all findings (including GPT-4) to Claude for synthesis...")
            return await self.synthesize_calculations_with_claude(all_calculations, api_responses)
        else:
            print("    No calculations found, using fallback")
            return self.get_fallback_calculations()
    
    def convert_excel_to_js(self, excel_formula: str) -> str:
        """Convert Excel formula to JavaScript"""
        # Basic conversion - would need enhancement for complex formulas
        js = excel_formula.replace('=', '')
        js = js.replace('SUM(', 'sum(')
        js = js.replace('AVERAGE(', 'average(')
        js = js.replace('COUNT(', 'count(')
        js = js.replace('IF(', 'if(')
        
        return f"""
function excelFormula() {{
    // Original Excel: {excel_formula}
    // TODO: Implement Excel formula conversion
    return 0;
}}"""
    
    async def synthesize_calculations_with_claude(self, found_calculations: List[Dict], api_responses: List[Dict]) -> List[Dict]:
        """Use Claude to synthesize all found calculations into coherent formulas"""
        print("  â†’ Claude synthesis of calculations")
        
        # Prepare data for Claude
        synthesis_data = {
            'excel_formulas': [c for c in found_calculations if c.get('source') == 'excel'][:5],
            'reverse_engineered': [c for c in found_calculations if c.get('source') == 'reverse_engineering'][:5],
            'api_triggers': [c for c in found_calculations if c.get('source') == 'api_trigger'][:5],
            'source_code': [c for c in found_calculations if c.get('source') == 'source_code'][:5],
            'patterns': [c for c in found_calculations if c.get('type') in ['constant', 'percentage']][:5],
            'api_responses': [{'endpoint': r['endpoint'], 'data': str(r.get('data', ''))[:500]} for r in api_responses[:3]]
        }
        
        claude_prompt = f"""
Analyze these discovered calculations and API responses to create the ACTUAL formulas used by the system.

Discovered Calculations:
{json.dumps(synthesis_data, indent=2)}

Based on all this evidence, create the definitive calculation formulas.

Return a JSON array with the ACTUAL formulas:
[
  {{
    "name": "calculateRentRoll",
    "description": "what this calculates",
    "formula": "EXACT mathematical expression based on evidence",
    "variables": ["var1", "var2"],
    "confidence": "high/medium/low",
    "evidence": "which discovery method confirmed this",
    "javascript": "function implementation"
  }}
]

Focus on the most important calculations for property management.
"""
        
        try:
            message = await asyncio.to_thread(
                self.anthropic_client.messages.create,
                model="claude-opus-4-1-20250805",
                max_tokens=3000,
                temperature=0,
                messages=[{"role": "user", "content": claude_prompt}]
            )
            
            response_text = message.content[0].text
            json_match = re.search(r'\[.*\]', response_text, re.DOTALL)
            
            if json_match:
                synthesized = json.loads(json_match.group())
                print(f"  âœ“ Claude synthesized {len(synthesized)} definitive calculations")
                
                # Add JavaScript implementations if not present
                for calc in synthesized:
                    if 'javascript' not in calc:
                        calc['javascript'] = self.generate_calculation_function(calc)
                    calc['verified'] = calc.get('confidence') == 'high'
                
                return synthesized
                
                # PRESERVE GPT-4 FORMULAS
                gpt4_originals = [c for c in found_calculations if c.get('is_gpt4')]
                if gpt4_originals:
                    synthesized_names = {calc['name'] for calc in synthesized}
                    for gpt4_calc in gpt4_originals:
                        if gpt4_calc['name'] not in synthesized_names:
                            print(f"    âš ï¸ Re-adding missing GPT-4 formula: {gpt4_calc['name']}")
                            synthesized.append(gpt4_calc)
                    print(f"  âœ“ Ensured {len(gpt4_originals)} GPT-4 formulas are preserved")
                
                return synthesized
                
                # PRESERVE GPT-4 FORMULAS
                gpt4_originals = [c for c in found_calculations if c.get('is_gpt4')]
                if gpt4_originals:
                    synthesized_names = {calc['name'] for calc in synthesized}
                    for gpt4_calc in gpt4_originals:
                        if gpt4_calc['name'] not in synthesized_names:
                            print(f"    âš ï¸ Re-adding missing GPT-4 formula: {gpt4_calc['name']}")
                            synthesized.append(gpt4_calc)
                    print(f"  âœ“ Ensured {len(gpt4_originals)} GPT-4 formulas are preserved")
                
                return synthesized


            else:
                return found_calculations[:10] if found_calculations else self.get_fallback_calculations()
                
        except Exception as e:
            logger.error(f"Claude synthesis error: {e}")
            return found_calculations[:10] if found_calculations else self.get_fallback_calculations()
        
        # Limit data for Claude (avoid token limits)
        api_data_summary = []
        for resp in api_responses[:5]:  # First 5 responses
            api_data_summary.append({
                'endpoint': resp['endpoint'],
                'data': resp['data'] if isinstance(resp['data'], dict) else str(resp['data'])[:500]
            })
        
        claude_prompt = f"""
Analyze these API responses from a property management system and identify all calculations and formulas.

API Responses:
{json.dumps(api_data_summary, indent=2)}

Extract:
1. Any mathematical formulas found
2. Relationships between data fields
3. Calculated values and their source data

Return a JSON array with this structure:
[
  {{
    "name": "calculation_name",
    "description": "what this calculates",
    "formula": "mathematical expression",
    "variables": ["var1", "var2"],
    "sample_data": {{}},
    "source_endpoint": "api_endpoint"
  }}
]

Focus on finding calculations like:
- Rent roll (sum of rents)
- Occupancy rate (occupied/total)
- Late fees (percentage of rent)
- Total revenue
- Outstanding balances
"""
        
        try:
            message = await asyncio.to_thread(
                self.anthropic_client.messages.create,
                model="claude-opus-4-1-20250805",
                max_tokens=2000,
                temperature=0,
                messages=[{"role": "user", "content": claude_prompt}]
            )
            
            response_text = message.content[0].text
            json_match = re.search(r'\[.*\]', response_text, re.DOTALL)
            
            if json_match:
                claude_calculations = json.loads(json_match.group())
                print(f"  âœ“ Claude identified {len(claude_calculations)} calculations")
                
                # Generate JavaScript implementations
                verified_calculations = []
                
                for calc in claude_calculations:
                    # Mark as verified based on confidence from Claude
                    calc['verified'] = True  # Trust Claude's analysis
                    print(f"    âœ“ Processed: {calc['name']}")
                    
                    # Generate JavaScript implementation
                    calc['javascript'] = self.generate_calculation_function(calc)
                    verified_calculations.append(calc)
                
                # Store API responses in Supabase for future analysis
                try:
                    for response in api_responses:
                        self.supabase.table('api_responses').insert({
                            'page_url': main_content.get('url'),
                            'endpoint': response['endpoint'],
                            'response_data': response['data'],
                            'extracted_formulas': [c for c in verified_calculations if c.get('source_endpoint') == response['endpoint']],
                            'captured_at': response['timestamp']
                        }).execute()
                except Exception as e:
                    print(f"    âš ï¸ Could not store API responses: {e}")
                
                
                
                # PRESERVE GPT-4 FORMULAS (from found_calculations)
                if 'found_calculations' in locals():
                    gpt4_originals = [c for c in found_calculations if c.get('is_gpt4')]
                    if gpt4_originals:
                        verified_names = {calc['name'] for calc in verified_calculations}
                        for gpt4_calc in gpt4_originals:
                            if gpt4_calc['name'] not in verified_names:
                                print(f"    âš ï¸ Re-adding missing GPT-4 formula: {gpt4_calc['name']}")
                                # Ensure JavaScript is present
                                if 'javascript' not in gpt4_calc:
                                    gpt4_calc['javascript'] = self.generate_calculation_function(gpt4_calc)
                                verified_calculations.append(gpt4_calc)
                        print(f"  âœ“ Preserved {len(gpt4_originals)} GPT-4 formulas in final result")
                
                
                
                # PRESERVE GPT-4 FORMULAS (from found_calculations)
                if 'found_calculations' in locals():
                    gpt4_originals = [c for c in found_calculations if c.get('is_gpt4')]
                    if gpt4_originals:
                        verified_names = {calc['name'] for calc in verified_calculations}
                        for gpt4_calc in gpt4_originals:
                            if gpt4_calc['name'] not in verified_names:
                                print(f"    âš ï¸ Re-adding missing GPT-4 formula: {gpt4_calc['name']}")
                                # Ensure JavaScript is present
                                if 'javascript' not in gpt4_calc:
                                    gpt4_calc['javascript'] = self.generate_calculation_function(gpt4_calc)
                                verified_calculations.append(gpt4_calc)
                        print(f"  âœ“ Preserved {len(gpt4_originals)} GPT-4 formulas in final result")
                
                return verified_calculations if verified_calculations else self.get_fallback_calculations()
                
            else:
                print("  âš ï¸ No calculations found by Claude")
                return self.get_fallback_calculations()
                
        except Exception as e:
            logger.error(f"Claude analysis error: {e}")
            return self.get_fallback_calculations()

    def generate_calculation_function(self, calc: Dict) -> str:
        """Generate JavaScript function from calculation"""
        name = calc.get('name', 'unknownCalc')
        formula = calc.get('formula', '')
        variables = calc.get('variables', [])
        description = calc.get('description', '')
        
        # Generate more specific functions based on the calculation type
        if 'rent' in name.lower() or 'roll' in name.lower():
            return f"""
async function {name}() {{
    try {{
        // {description}
        // Formula: {formula}
        const {{ data, error }} = await supabase
            .from('units')
            .select('rent, status')
            .eq('status', 'occupied');
        
        if (error) throw error;
        
        // Apply formula: {formula}
        const total = data.reduce((sum, unit) => sum + (parseFloat(unit.rent) || 0), 0);
        
        return total;
    }} catch (error) {{
        console.error('Error in {name}:', error);
        return 0;
    }}
}}"""
        elif 'occupancy' in name.lower():
            return f"""
async function {name}() {{
    try {{
        // {description}
        // Formula: {formula}
        const {{ data, error }} = await supabase
            .from('units')
            .select('status');
        
        if (error) throw error;
        
        const totalUnits = data.length;
        const occupiedUnits = data.filter(unit => unit.status === 'occupied').length;
        
        return totalUnits > 0 ? ((occupiedUnits / totalUnits) * 100).toFixed(2) : 0;
    }} catch (error) {{
        console.error('Error in {name}:', error);
        return 0;
    }}
}}"""
        else:
            # Generic calculation function
            return f"""
async function {name}() {{
    try {{
        // {description}
        // Formula: {formula}
        // Variables: {', '.join(variables)}
        const {{ data, error }} = await supabase
            .from('properties')
            .select('*');
        
        if (error) throw error;
        
        // TODO: Implement actual formula based on data structure
        // Formula to implement: {formula}
        let result = 0;
        
        return result;
    }} catch (error) {{
        console.error('Error in {name}:', error);
        return 0;
    }}
}}"""
        
    def get_fallback_calculations(self) -> List[Dict]:
        """Fallback calculations if Claude fails"""
        return [
            {
                "name": "calculateRentRoll",
                "description": "Total monthly rent from all units",
                "formula": "SUM(unit_rents)",
                "supabase_table": "units",
                "javascript": """
async function calculateRentRoll() {
    try {
        const { data, error } = await supabase
            .from('units')
            .select('rent');
        
        if (error) throw error;
        
        return data.reduce((total, unit) => total + (parseFloat(unit.rent) || 0), 0);
    } catch (error) {
        console.error('Error calculating rent roll:', error);
        return 0;
    }
}""",
                "variables": ["units", "rent"]
            },
            {
                "name": "calculateOccupancyRate", 
                "description": "Percentage of occupied units",
                "formula": "(occupied_units / total_units) * 100",
                "supabase_table": "units",
                "javascript": """
async function calculateOccupancyRate() {
    try {
        const { data, error } = await supabase
            .from('units')
            .select('status');
        
        if (error) throw error;
        
        const totalUnits = data.length;
        const occupiedUnits = data.filter(unit => unit.status === 'occupied').length;
        
        return totalUnits > 0 ? ((occupiedUnits / totalUnits) * 100).toFixed(2) : 0;
    } catch (error) {
        console.error('Error calculating occupancy:', error);
        return 0;
    }
}""",
                "variables": ["units", "status"]
            }
        ]
        
    async def generate_beautiful_template(self, url: str, main_content: Dict, calculations: List[Dict]) -> str:
        """Generate BEAUTIFUL template with YOUR base.html + EXACT site content"""
        print("  â†’ Creating beautiful template")
        
        # Determine template path from URL
        url_path = url.replace(self.target_base, '').strip('/')
        
        # Handle home page
        if not url_path or url_path == '':
            template_path = self.templates_dir / 'index.html'
        elif url_path == 'reports':
            template_path = self.templates_dir / 'reports' / 'index.html'
        else:
            parts = url_path.split('/')
            if len(parts) == 1:
                # Single level path
                template_path = self.templates_dir / f"{parts[0]}.html"
            else:
                # Multi-level path
                dir_path = self.templates_dir / parts[0]
                dir_path.mkdir(parents=True, exist_ok=True)
                filename = parts[-1].replace('-', '_') + '.html'
                template_path = dir_path / filename
            
        template_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Clean the main content HTML
        soup = BeautifulSoup(main_content['html'], 'html.parser')
        
        # Replace site branding with AIVIIZN
        for element in soup.find_all(string=True):
            if 'celtic' in element.lower():
                element.replace_with(
                    element.replace('Celtic Property Management', 'AIVIIZN')
                           .replace('Celtic', 'AIVIIZN')
                )
                
        # Enhance the HTML with beautiful styling
        enhanced_html = self.enhance_content(str(soup))
        
        # Generate calculation JavaScript
        calc_js = self.generate_calculation_js(calculations)
        
        # DEBUG: Verify calculations
        print(f"  ðŸ“Š Calculations in template: {len(calculations)}")
        if calculations:
            gpt4_in_template = sum(1 for c in calculations if c.get('is_gpt4'))
            print(f"  ðŸ¤– GPT-4 formulas: {gpt4_in_template}")
            for calc in calculations[:3]:
                marker = "GPT-4" if calc.get('is_gpt4') else calc.get('source', '?')
                print(f"     [{marker}] {calc.get('name', 'unnamed')}")
        
        print(f"  ðŸ“ Generated {len(calc_js)} chars of JavaScript")
        if len(calc_js) < 50:
            print("  âš ï¸ WARNING: JavaScript too short!")
        
        # Create the template that extends base.html
        # Clean title - remove any site references
        clean_title = main_content.get('title', 'Reports')
        clean_title = clean_title.replace('AppFolio Property Manager', '').replace('- AppFolio', '').replace('AppFolio', '').strip()
        if clean_title.endswith(' -'):
            clean_title = clean_title[:-2].strip()
        
        # FIX: Use the actual anon key value, not os.getenv in the template
        template_content = f'''{{%% extends "base.html" %%}}

{{%% block title %%}}AIVIIZN - {clean_title}{{%% endblock %%}}

{{%% block styles %%}}
<style>
/* EXACT site styles enhanced for beauty */
.main-content {{
    padding: 20px;
    background: #ffffff;
    min-height: calc(100vh - 120px);
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
}}

/* Beautiful page header */
.page-header {{
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 24px;
    padding-bottom: 16px;
    border-bottom: 2px solid #e9ecef;
}}

.page-title {{
    font-size: 28px;
    font-weight: 600;
    color: #212529;
    margin: 0;
}}

.page-actions {{
    display: flex;
    gap: 12px;
}}

.btn-action {{
    padding: 8px 16px;
    font-size: 13px;
    border: 1px solid #ddd;
    background: white;
    color: #333;
    cursor: pointer;
    border-radius: 4px;
    transition: all 0.2s ease;
    text-decoration: none;
    display: inline-flex;
    align-items: center;
    gap: 6px;
}}

.btn-action:hover {{
    background: #f8f9fa;
    transform: translateY(-1px);
    box-shadow: 0 2px 8px rgba(0,0,0,0.1);
}}

.btn-primary {{
    background: #0B5394;
    color: white;
    border-color: #0B5394;
}}

.btn-primary:hover {{
    background: #073763;
    border-color: #073763;
}}

/* Beautiful data tables */
.data-table {{
    width: 100%;
    background: white;
    border-radius: 8px;
    overflow: hidden;
    box-shadow: 0 2px 12px rgba(0,0,0,0.05);
    margin: 20px 0;
}}

.data-table table {{
    width: 100%;
    border-collapse: collapse;
    font-size: 13px;
}}

.data-table th {{
    background: #f8f9fa;
    color: #495057;
    font-weight: 600;
    padding: 12px 16px;
    text-align: left;
    border-bottom: 2px solid #dee2e6;
    font-size: 12px;
    text-transform: uppercase;
    letter-spacing: 0.5px;
}}

.data-table td {{
    padding: 12px 16px;
    border-bottom: 1px solid #f1f3f5;
    color: #212529;
}}

.data-table tbody tr:hover {{
    background: #f8f9fa;
    transform: scale(1.001);
    transition: all 0.15s ease;
}}

/* Beautiful forms */
.form-container {{
    background: white;
    padding: 24px;
    border-radius: 8px;
    box-shadow: 0 2px 8px rgba(0,0,0,0.05);
    margin: 20px 0;
}}

.form-row {{
    display: flex;
    gap: 16px;
    margin-bottom: 16px;
    align-items: center;
}}

.form-control {{
    padding: 8px 12px;
    border: 1px solid #ced4da;
    border-radius: 4px;
    font-size: 13px;
    transition: border-color 0.15s ease;
}}

.form-control:focus {{
    border-color: #0B5394;
    box-shadow: 0 0 0 3px rgba(11, 83, 148, 0.1);
    outline: none;
}}

.form-label {{
    font-size: 13px;
    color: #495057;
    font-weight: 500;
    margin-right: 8px;
    white-space: nowrap;
}}

/* Beautiful metrics cards */
.metrics-grid {{
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
    gap: 20px;
    margin: 24px 0;
}}

.metric-card {{
    background: white;
    padding: 24px;
    border-radius: 8px;
    box-shadow: 0 2px 8px rgba(0,0,0,0.05);
    border: 1px solid #e9ecef;
    transition: all 0.3s ease;
}}

.metric-card:hover {{
    transform: translateY(-2px);
    box-shadow: 0 4px 20px rgba(0,0,0,0.1);
}}

.metric-label {{
    font-size: 12px;
    color: #6c757d;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    margin-bottom: 8px;
    font-weight: 600;
}}

.metric-value {{
    font-size: 32px;
    font-weight: 700;
    color: #212529;
    margin-bottom: 4px;
}}

.metric-change {{
    font-size: 14px;
    display: flex;
    align-items: center;
    gap: 4px;
}}

.metric-change.positive {{
    color: #28a745;
}}

.metric-change.negative {{
    color: #dc3545;
}}

/* Loading states */
.loading {{
    opacity: 0.7;
    pointer-events: none;
}}

.loading::after {{
    content: '';
    position: absolute;
    top: 50%;
    left: 50%;
    width: 20px;
    height: 20px;
    margin: -10px 0 0 -10px;
    border: 2px solid #f3f3f3;
    border-top: 2px solid #0B5394;
    border-radius: 50%;
    animation: spin 1s linear infinite;
}}

@keyframes spin {{
    0% {{ transform: rotate(0deg); }}
    100% {{ transform: rotate(360deg); }}
}}

/* Beautiful animations */
.slide-in {{
    animation: slideIn 0.5s ease-out;
}}

@keyframes slideIn {{
    from {{
        opacity: 0;
        transform: translateY(20px);
    }}
    to {{
        opacity: 1;
        transform: translateY(0);
    }}
}}
</style>
{{%% endblock %%}}

{{%% block content %%}}
<div class="main-content slide-in">
    {enhanced_html}
</div>

<!-- Supabase client -->
<script src="https://unpkg.com/@supabase/supabase-js@2"></script>

<script>
// Initialize Supabase with anon key (safe for client-side)
const supabaseUrl = '{self.supabase_url}';
const supabaseKey = '{self.supabase_anon_key}';  // FIX: Use anon key, not service key
const supabase = window.supabase.createClient(supabaseUrl, supabaseKey);

// API response data for calculations
const apiResponses = {json.dumps(main_content.get('api_responses', []))};

{calc_js}

// Initialize page
document.addEventListener('DOMContentLoaded', async function() {{
    console.log('ðŸš€ AIVIIZN page initialized');
    console.log('ðŸ“Š API responses available:', apiResponses.length);
    
    // Load real data
    await loadPageData();
    
    // Update calculations
    await updateAllCalculations();
    
    // Set up real-time updates
    setupRealtimeUpdates();
    
    // Add beautiful interactions
    enhanceInteractions();
}});

async function loadPageData() {{
    try {{
        // Check if we have API response data to use
        if (apiResponses && apiResponses.length > 0) {{
            console.log('âœ“ Using captured API data');
            // Process API responses
            apiResponses.forEach(response => {{
                if (response.data) {{
                    // Use the actual API data
                    processApiData(response.data);
                }}
            }});
        }} else {{
            // Fallback to loading from Supabase
            const {{{{ data: properties, error }}}} = await supabase
                .from('properties')
                .select('*');
                
            if (error) throw error;
            
            console.log('âœ“ Data loaded from Supabase:', properties?.length || 0, 'records');
            updateDataTables(properties || []);
        }}
        
    }} catch (error) {{
        console.error('Error loading data:', error);
    }}
}}

function processApiData(data) {{
    // Process captured API data
    if (data.units) {{
        updateDataTables(data.units);
    }}
    if (data.total) {{
        document.getElementById('totalRevenue').textContent = '$' + data.total.toLocaleString();
    }}
    if (data.occupancy_rate) {{
        document.getElementById('occupancyRate').textContent = data.occupancy_rate + '%';
    }}
}}

async function updateAllCalculations() {{
    try {{
        // Update all metric cards with real calculations
        {self.generate_metric_updates(calculations)}
        
        console.log('âœ“ All calculations updated');
        
    }} catch (error) {{
        console.error('Error updating calculations:', error);
    }}
}}

function setupRealtimeUpdates() {{
    // Subscribe to database changes for real-time updates
    supabase
        .channel('public:properties')
        .on('postgres_changes', 
            {{ event: '*', schema: 'public', table: 'properties' }}, 
            (payload) => {{
                console.log('ðŸ”„ Real-time update received:', payload);
                loadPageData();
                updateAllCalculations();
            }}
        )
        .subscribe();
}}

function enhanceInteractions() {{
    // Add beautiful hover effects and interactions
    document.querySelectorAll('.metric-card').forEach((card, index) => {{
        card.style.animationDelay = `${{index * 0.1}}s`;
        card.classList.add('slide-in');
    }});
    
    // Add loading states to buttons
    document.querySelectorAll('.btn-action').forEach(btn => {{
        btn.addEventListener('click', function(e) {{
            if (!this.classList.contains('loading')) {{
                this.classList.add('loading');
                setTimeout(() => this.classList.remove('loading'), 1000);
            }}
        }});
    }});
}}

function updateDataTables(data) {{
    // Update tables with real data
    const tableBody = document.querySelector('.data-table tbody');
    if (tableBody && data.length > 0) {{
        tableBody.innerHTML = data.map(item => `
            <tr>
                <td>${{item.name || item.unit || 'N/A'}}</td>
                <td>${{item.status || 'Active'}}</td>
                <td>${{item.rent || item.value || '0'}}</td>
                <td>
                    <button class="btn-action" onclick="viewDetails(${{item.id}})">
                        <i class="fas fa-eye"></i> View
                    </button>
                </td>
            </tr>
        `).join('');
    }}
}}

function viewDetails(id) {{
    // Navigate to details page
    window.location.href = `/details/${{id}}`;
}}

// Export functions for testing
window.AIVIIZNFunctions = {{
    loadPageData,
    updateAllCalculations,
    processApiData,
    {", ".join([calc["name"] for calc in calculations if "name" in calc])}
}};
</script>
{{%% endblock %%}}'''

        # Write the template
        with open(template_path, 'w', encoding='utf-8') as f:
            f.write(template_content)
            
        print(f"  âœ“ Beautiful template created: {template_path}")
        
        return str(template_path)
        
    def enhance_content(self, html: str) -> str:
        """
        Enhance the content to be BEAUTIFUL
        """
        soup = BeautifulSoup(html, 'html.parser')
        
        # Enhance page structure
        if soup.find('h1'):
            soup.find('h1')['class'] = 'page-title'
            
        # Wrap page title and add actions
        h1 = soup.find('h1')
        if h1:
            header_div = soup.new_tag('div', **{'class': 'page-header'})
            actions_div = soup.new_tag('div', **{'class': 'page-actions'})
            
            # Add action buttons
            for action in ['Print', 'Export', 'Generate Report']:
                btn = soup.new_tag('button', **{'class': 'btn-action btn-primary' if 'Generate' in action else 'btn-action'})
                btn.string = action
                actions_div.append(btn)
                
            h1.wrap(header_div)
            header_div.append(actions_div)
        
        # Enhance tables
        for table in soup.find_all('table'):
            table['class'] = 'table'
            table.wrap(soup.new_tag('div', **{'class': 'data-table'}))
            
        # Enhance forms
        for form in soup.find_all('form'):
            form['class'] = 'form-container'
            
            # Wrap form elements
            for input_elem in form.find_all(['input', 'select']):
                if not input_elem.parent.name == 'div':
                    wrapper = soup.new_tag('div', **{'class': 'form-row'})
                    input_elem.wrap(wrapper)
                    
        # Add metrics if not present
        if not soup.find(class_='metric'):
            metrics_div = soup.new_tag('div', **{'class': 'metrics-grid'})
            
            metrics = [
                {'label': 'Total Revenue', 'value': '$0', 'id': 'totalRevenue'},
                {'label': 'Occupancy Rate', 'value': '0%', 'id': 'occupancyRate'},
                {'label': 'Outstanding Balance', 'value': '$0', 'id': 'outstandingBalance'},
                {'label': 'Monthly Rent Roll', 'value': '$0', 'id': 'rentRoll'}
            ]
            
            for metric in metrics:
                card = soup.new_tag('div', **{'class': 'metric-card'})
                label = soup.new_tag('div', **{'class': 'metric-label'})
                label.string = metric['label']
                value = soup.new_tag('div', **{'class': 'metric-value', 'id': metric['id']})
                value.string = metric['value']
                change = soup.new_tag('div', **{'class': 'metric-change positive'})
                change.append(soup.new_tag('i', **{'class': 'fas fa-arrow-up'}))
                change.append(' +5.2% from last month')
                
                card.append(label)
                card.append(value) 
                card.append(change)
                metrics_div.append(card)
                
            # Insert metrics after header or at beginning
            header = soup.find(class_='page-header')
            if header:
                header.insert_after(metrics_div)
            else:
                soup.insert(0, metrics_div)
                
        return str(soup)
        
    def generate_calculation_js(self, calculations: List[Dict]) -> str:
        """Generate JavaScript for all calculations"""
        js_functions = []
        gpt4_count = sum(1 for c in calculations if c.get("is_gpt4"))
        print(f"    â†’ Generating JS: {len(calculations)} total, {gpt4_count} from GPT-4")
        
        for calc in calculations:
            
            # Add GPT-4 marker comment if applicable
            if calc.get('is_gpt4'):
                js_functions.append(f'// ðŸ¤– GPT-4 Formula: {calc.get("name", "unnamed")}')
            js_functions.append(calc.get('javascript', ''))
            
        return '\n\n'.join(js_functions)
        
    def generate_metric_updates(self, calculations: List[Dict]) -> str:
        """Generate code to update metric displays"""
        updates = []
        
        for calc in calculations:
            name = calc.get('name', '')
            if 'rent' in name.lower():
                updates.append(f"""
        const {name}Result = await {name}();
        const rentElement = document.getElementById('rentRoll');
        if (rentElement) {{
            rentElement.textContent = '$' + parseFloat({name}Result).toLocaleString();
        }}""")
            elif 'occupancy' in name.lower():
                updates.append(f"""
        const {name}Result = await {name}();
        const occupancyElement = document.getElementById('occupancyRate');
        if (occupancyElement) {{
            occupancyElement.textContent = {name}Result + '%';
        }}""")
                
        return '\n'.join(updates) if updates else "// No specific metric updates needed"
        
    async def store_in_supabase_real(self, url: str, main_content: Dict, calculations: List[Dict], template_path: str):
        """
        Store REAL data in Supabase - normalized, no duplicates
        """
        print("  â†’ Storing in Supabase database")
        
        try:
            # Store page record
            page_data = {
                'url': url,
                'title': main_content.get('title', ''),
                'page_type': 'report',
                'processed_at': datetime.now().isoformat(),
                'calculations_count': len(calculations)
            }
            
            # Use UPSERT to avoid duplicates
            result = self.supabase.table('pages').upsert(
                page_data,
                on_conflict='url'
            ).execute()
            
            if result.data:
                page_id = result.data[0]['id']
                print("    âœ“ Page record stored (upserted)")
            else:
                print("    âš ï¸ No page ID returned, checking existing...")
                existing = self.supabase.table('pages').select('id').eq('url', url).execute()
                if existing.data:
                    page_id = existing.data[0]['id']
                else:
                    print("    âŒ Failed to get page ID")
                    return
                
            # Store calculations (upsert to avoid duplicates)
            for calc in calculations:
                calc_data = {
                    'page_id': page_id,
                    'formula_type': calc.get('name', ''),
                    'formula_expression': calc.get('formula', ''),
                    'variables': calc.get('variables', []),
                    'javascript_code': calc.get('javascript', ''),
                    'context_description': calc.get('description', ''),
                    'verification_status': 'verified' if calc.get('verified') else 'pending'
                }
                
                # Upsert calculation
                self.supabase.table('calculations').upsert(
                    calc_data,
                    on_conflict='page_id,formula_type'
                ).execute()
                    
            print(f"    âœ“ Stored {len(calculations)} calculations")
            
        except Exception as e:
            logger.error(f"Error storing in Supabase: {e}")
            print(f"    âš   Error storing data: {e}")
            
    def discover_links_real(self, main_content: Dict) -> List[str]:
        """
        Discover new links from the content
        """
        print("  â†’ Discovering new page links")
        
        # Parse HTML to find actual links
        soup = BeautifulSoup(main_content.get('html', ''), 'html.parser')
        found_links = set()
        
        # Debug: show how many links we're examining
        all_links = soup.find_all('a', href=True)
        print(f"    Examining {len(all_links)} links in content...")
        
        # Find all links in the content
        for link in all_links:
            href = link['href']
            # Convert relative URLs to absolute
            if href.startswith('/'):
                full_url = self.target_base + href
            elif href.startswith('http'):
                full_url = href
            else:
                continue
                
            # Only process target site links
            if self.target_base in full_url:
                # Clean up URL (remove query params and fragments)
                full_url = full_url.split('?')[0].split('#')[0]
                
                # Skip certain types of links
                skip_patterns = ['/sign_out', '/logout', '.pdf', '.jpg', '.png', '/download', '/help', '#', 'javascript:', 'mailto:']
                if any(pattern in full_url.lower() for pattern in skip_patterns):
                    continue
                    
                if full_url not in self.discovered_links and full_url not in self.processed_pages:
                    found_links.add(full_url)
                    print(f"      âœ“ Found: {full_url.replace(self.target_base, '')}")
        
        # Add all found links to discovered_links
        new_links = list(found_links)
        self.discovered_links.extend(new_links)
                
        print(f"    âœ“ Total new pages found: {len(new_links)}")
        return new_links


# Main execution
async def main():
    """Run the real agent with persistent browser"""
    agent = AIVIIZNRealAgent()
    
    try:
        await agent.run()
        print("\nðŸŽ‰ SESSION COMPLETE!")
        print("âœ“ Beautiful templates created")
        print("âœ“ API responses captured")
        print("âœ“ Calculations verified with Claude + GPT-4")
        print("âœ“ Data normalized in Supabase")
        print("âœ“ Browser closed cleanly")
        print("âœ“ Ready for production use")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ Stopped by user")
        agent.save_state()
        print("âœ“ Progress saved")
        if hasattr(agent, 'browser') and agent.browser:
            await agent.close_browser()
        
    except Exception as e:
        logger.error(f"Agent error: {e}")
        agent.save_state()
        if hasattr(agent, 'browser') and agent.browser:
            await agent.close_browser()
        raise


if __name__ == "__main__":
    # Install required packages if needed
    try:
        import playwright
        import anthropic
        import supabase
        import bs4
        from openai import AsyncOpenAI
    except ImportError as e:
        print(f"Missing required package: {e}")
        print("Run: pip install playwright anthropic supabase beautifulsoup4 python-dotenv openai")
        sys.exit(1)
        
    # Run the agent
    asyncio.run(main())